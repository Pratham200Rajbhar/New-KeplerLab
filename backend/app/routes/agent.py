"""Agent routes — code execution and research, all routed through LangGraph agent.

Provides:
- POST /agent/execute — Direct Python code execution (user-authored code, SSE stream)
- POST /agent/analyze — NL → code → execute, via LangGraph DATA_ANALYSIS intent (SSE stream)
- POST /agent/research — Deep research, via LangGraph RESEARCH intent (SSE stream)
- GET  /agent/status/{job_id} — Execution status

All endpoints share the same single execution engine: the LangGraph agent graph.
/execute is the only exception — it accepts user-written code directly for the code REPL,
bypassing NL understanding but still running through the same sandbox.
"""

import json
import logging
import os
import uuid
import time
from fastapi import APIRouter, Depends, Query
from fastapi.responses import JSONResponse, StreamingResponse, FileResponse
from pydantic import BaseModel, Field
from typing import Optional, List

from app.services.agent.persistence import log_code_execution
from app.services.auth import get_current_user
from app.routes.utils import require_file_token
from app.core.config import settings

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/agent", tags=["agent"])

_SSE_HEADERS = {
    "Cache-Control": "no-cache",
    "Connection": "keep-alive",
    "X-Accel-Buffering": "no",
}


class ExecuteRequest(BaseModel):
    """Direct Python code execution (code-editor / REPL use-case)."""
    code: str = Field(..., min_length=1, max_length=50000)
    notebook_id: str
    timeout: int = Field(15, ge=1, le=120)


class AnalyzeRequest(BaseModel):
    """NL data-analysis request.  material_ids must be uploaded CSV materials."""
    query: str = Field(..., min_length=1, max_length=10000)
    notebook_id: str
    material_ids: Optional[List[str]] = None


class ResearchRequest(BaseModel):
    """Deep web-research request."""
    query: str = Field(..., min_length=1, max_length=5000)
    notebook_id: str
    material_ids: Optional[List[str]] = None


# ── /execute — direct sandbox (user writes the code) ─────────

@router.post("/execute")
async def execute_code_endpoint(
    request: ExecuteRequest,
    current_user=Depends(get_current_user),
):
    """Execute user-authored Python code directly in the sandbox with SSE streaming.

    This is the code-REPL path.  The code is not generated by the LLM; it is
    provided verbatim by the user.  Security validation still applies.

    SSE events:  stdout → result/error → done
    """
    from app.services.code_execution.executor import execute_code
    import asyncio

    session_id = str(uuid.uuid4())
    queue: asyncio.Queue = asyncio.Queue()

    async def on_stdout_line(line: str):
        await queue.put({"type": "stdout", "line": line})

    async def execute_task():
        try:
            result = await execute_code(
                code=request.code,
                timeout=min(request.timeout, settings.CODE_EXECUTION_TIMEOUT),
                on_stdout_line=on_stdout_line,
            )
            await log_code_execution(
                user_id=str(current_user.id),
                notebook_id=request.notebook_id,
                code=request.code,
                stdout=result.get("stdout", ""),
                stderr=result.get("stderr", ""),
                exit_code=result.get("exit_code", -1),
                has_chart=result.get("chart_base64") is not None,
                elapsed=result.get("elapsed", 0.0),
            )
            await queue.put({"type": "result", "data": result})
        except Exception as e:
            logger.error("Execute task failed: %s", e)
            await queue.put({"type": "error", "error": str(e)})

    task = asyncio.create_task(execute_task())

    async def event_generator():
        try:
            yield f"event: start\ndata: {json.dumps({'session_id': session_id})}\n\n"
            while True:
                msg = await queue.get()
                if msg["type"] == "stdout":
                    yield f"event: stdout\ndata: {json.dumps({'session_id': session_id, 'line': msg['line']})}\n\n"
                elif msg["type"] == "result":
                    yield f"event: result\ndata: {json.dumps(msg['data'])}\n\n"
                    break
                elif msg["type"] == "error":
                    yield f"event: error\ndata: {json.dumps({'session_id': session_id, 'error': msg['error']})}\n\n"
                    break
        except Exception as e:
            logger.error("event_generator failed: %s", e)
            yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"
        finally:
            # Always emit done and cancel hanging task
            yield f"event: done\ndata: {json.dumps({'session_id': session_id})}\n\n"
            if not task.done():
                task.cancel()

    return StreamingResponse(event_generator(), media_type="text/event-stream", headers=_SSE_HEADERS)


# ── /analyze — routes through LangGraph agent (DATA_ANALYSIS) ─

@router.post("/analyze")
async def analyze_data_endpoint(
    request: AnalyzeRequest,
    current_user=Depends(get_current_user),
):
    """NL data-analysis — routed through LangGraph agent with DATA_ANALYSIS intent.

    Pre-sets intent and plan so the agent skips redundant detection/planning.
    material_ids should point to uploaded CSV materials.

    SSE events: start → step → token → code_stdout → meta → done
    """
    from app.services.agent.graph import run_agent_stream
    from app.services.agent.state import AgentState

    session_id = str(uuid.uuid4())

    initial_state: AgentState = {
        "user_message": request.query,
        "user_id": str(current_user.id),
        "notebook_id": request.notebook_id,
        "material_ids": request.material_ids or [],
        "session_id": session_id,
        # Pre-set intent so intent_detection + planner are bypassed
        "intent": "DATA_ANALYSIS",
        "intent_confidence": 1.0,
        "plan": [{"tool": "python_tool", "description": "Analyze data and generate chart"}],
        "current_step": 0,
        "tool_results": [],
        "iterations": 0,
        "total_tokens": 0,
        "total_tool_calls": 0,
        "needs_retry": False,
        "step_retries": 0,
        "response": "",
        "agent_metadata": {},
    }

    async def generate():
        try:
            async for event in run_agent_stream(initial_state):
                yield event
        except Exception as e:
            logger.error("analyze stream failed: %s", e)
            yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"
            yield f"event: done\ndata: {json.dumps({'session_id': session_id})}\n\n"

    return StreamingResponse(generate(), media_type="text/event-stream", headers=_SSE_HEADERS)


# ── /research — routes through LangGraph agent (RESEARCH) ────

@router.post("/research")
async def research_endpoint(
    request: ResearchRequest,
    current_user=Depends(get_current_user),
):
    """Deep research — routed through LangGraph agent with RESEARCH intent.

    Pre-sets intent and plan so the agent skips redundant detection/planning.

    SSE events: start → step → token → meta → done
    """
    from app.services.agent.graph import run_agent_stream
    from app.services.agent.state import AgentState

    session_id = str(uuid.uuid4())

    initial_state: AgentState = {
        "user_message": request.query,
        "user_id": str(current_user.id),
        "notebook_id": request.notebook_id,
        "material_ids": request.material_ids or [],
        "session_id": session_id,
        # Pre-set intent so intent_detection + planner are bypassed
        "intent": "RESEARCH",
        "intent_confidence": 1.0,
        "plan": [{"tool": "research_tool", "description": "Conduct deep research on the topic"}],
        "current_step": 0,
        "tool_results": [],
        "iterations": 0,
        "total_tokens": 0,
        "total_tool_calls": 0,
        "needs_retry": False,
        "step_retries": 0,
        "response": "",
        "agent_metadata": {},
    }

    async def generate():
        try:
            async for event in run_agent_stream(initial_state):
                yield event
        except Exception as e:
            logger.error("research stream failed: %s", e)
            yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"
            yield f"event: done\ndata: {json.dumps({'session_id': session_id})}\n\n"

    return StreamingResponse(generate(), media_type="text/event-stream", headers=_SSE_HEADERS)


# ── /status — execution status placeholder ────────────────────

@router.get("/status/{job_id}")
async def execution_status(
    job_id: str,
    current_user=Depends(get_current_user),
):
    """Execution status — queries the job service for actual status."""
    from app.services.job_service import get_job

    job = await get_job(job_id, str(current_user.id))
    if not job:
        # Synchronous executions don't create jobs — treat as completed
        return JSONResponse(content={
            "job_id": job_id,
            "status": "completed",
            "message": "Synchronous execution — result was returned immediately",
        })

    return JSONResponse(content={
        "job_id": job_id,
        "status": job.status,
        "message": f"Job is {job.status}",
        "result": job.result if job.status == "completed" else None,
        "error": job.error if job.status == "failed" else None,
    })


# ── /files — list generated files ─────────────────────────────

@router.get("/files")
async def list_generated_files(
    session_id: str = Query(..., description="Chat session ID"),
    current_user=Depends(get_current_user),
):
    """List all files generated by the agent for a given session.

    Returns:
        {"files": [{name, url, size, type, created_at}]}
    """
    user_id = str(current_user.id)
    # Sanitize session_id to prevent path traversal
    safe_session_id = os.path.basename(session_id)
    output_dir = os.path.join(settings.GENERATED_OUTPUT_DIR, user_id, safe_session_id)

    if not os.path.isdir(output_dir):
        return JSONResponse(content={"files": []})

    files = []
    for filename in os.listdir(output_dir):
        filepath = os.path.join(output_dir, filename)
        if not os.path.isfile(filepath):
            continue

        stat = os.stat(filepath)
        ext = os.path.splitext(filename)[1].lower()
        type_map = {
            ".csv": "spreadsheet", ".xlsx": "spreadsheet", ".xls": "spreadsheet",
            ".docx": "document", ".pdf": "document",
            ".png": "image", ".jpg": "image", ".jpeg": "image", ".svg": "image",
            ".html": "web", ".json": "data", ".txt": "text",
        }

        files.append({
            "name": filename,
            "url": f"/agent/download/{user_id}/{safe_session_id}/{filename}",
            "size": stat.st_size,
            "type": type_map.get(ext, "file"),
            "created_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(stat.st_ctime)),
        })

    return JSONResponse(content={"files": files})


# ── /download — serve generated file ──────────────────────────

@router.get("/download/{user_id}/{session_id}/{filename}")
async def download_generated_file(
    user_id: str,
    session_id: str,
    filename: str,
    token: str = Query(..., description="Signed file access token"),
):
    """Download a generated file with token-based auth.

    Uses the same file token system as podcast downloads.
    Validates that the token's user matches the requested user_id.
    """
    # Verify the file token and get the token's user_id
    token_data = await require_file_token(token)

    # IDOR protection: verify the token owner matches the requested user
    token_user_id = getattr(token_data, "user_id", None) or (token_data.get("user_id") if isinstance(token_data, dict) else None)
    if not token_user_id:
        return JSONResponse(status_code=403, content={"detail": "Invalid token: missing user identity"})
    if str(token_user_id) != str(user_id):
        return JSONResponse(status_code=403, content={"detail": "Token user mismatch"})

    # Prevent path traversal on all path components
    safe_filename = os.path.basename(filename)
    safe_session_id = os.path.basename(session_id)
    safe_user_id = os.path.basename(user_id)
    filepath = os.path.join(settings.GENERATED_OUTPUT_DIR, safe_user_id, safe_session_id, safe_filename)

    if not os.path.isfile(filepath):
        return JSONResponse(status_code=404, content={"detail": "File not found"})

    # Determine content type
    ext = os.path.splitext(safe_filename)[1].lower()
    content_type_map = {
        ".csv": "text/csv",
        ".xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        ".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        ".pdf": "application/pdf",
        ".png": "image/png",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".svg": "image/svg+xml",
        ".html": "text/html",
        ".json": "application/json",
        ".txt": "text/plain",
    }
    media_type = content_type_map.get(ext, "application/octet-stream")

    return FileResponse(
        filepath,
        media_type=media_type,
        filename=safe_filename,
        headers={"Content-Disposition": f'attachment; filename="{safe_filename}"'},
    )
